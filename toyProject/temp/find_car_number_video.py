# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import cv2
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import pytesseract
from PIL import Image
import paho.mqtt.client as mqtt
import re
import time
car_number = ""
mqtt_broker_ip = "192.168.0.6"
port = 1883
topic = "car/number"
username = "dahyun_raspi"
password = "0101"  # ì„¤ì •í•œ ë¹„ë°€ë²ˆí˜¸

last_plate = None
last_time = 0
cooldown = 10 # 10ì´ˆ ì´ë‚´ ê°™ì€ ë²ˆí˜¸íŒì´ ì¸ì‹ë˜ì—ˆì„ ê²½ìš° ë¬´ì‹œ

# MQTT ì´ˆê¸° ì„¤ì • 
pattern = r'^\d{3}[ê°€-í£]\d{4}$'
client = mqtt.Client()
client.username_pw_set(username=username, password=password)
client.connect(mqtt_broker_ip, port, 60)
client.loop_start()

# contours box ì €ì¥ í•¨ìˆ˜
def draw_contours(contours):
    contours_dict = []
    # ê²€ì¶œëœ ì˜ì—­ ì €ì¥
    for contour in contours:
        x, y, w, h = cv2.boundingRect(contour)
        contours_dict.append({
            'contour':contour,
            'x': x,
            'y': y,
            'w': w,
            'h': h,
            'cx': x + (h / 2), # ê°€ë¡œ ê¸¸ì´
            'cy': y + (h / 2), # ì„¸ë¡œ ê¸¸ì´
        })
    print(f"[DEBUG]ê²€ì¶œëœ ì˜ì—­ ì €ì¥: {len(contours_dict)}ê°œ")    
    return contours_dict

# Contours ì—ì„œ ë²ˆí˜¸íŒ ì˜ì—­ ì°¾ê¸° -----------
def find_possible_contours(contours_dict):
    MIN_AREA, MIN_WIDTH, MIN_HEIGHT = 80, 2, 8
    MIN_RATIO, MAX_RATIO = 0.25, 1.0

    possible_contours = []
    cnt = 0
    for c in contours_dict:
        area = c['w'] * c['h']
        ratio = c['w'] / c['h']

        if area > MIN_AREA and c['w'] > MIN_WIDTH and c['h'] > MIN_HEIGHT and MIN_RATIO < ratio < MAX_RATIO:
            c['idx'] = cnt
            cnt += 1
            possible_contours.append(c)

    print(f"[DEBUG]ì˜ì—­ í¬ê¸°ë¡œ í•„í„°ë§ëœ contours: {len(possible_contours)}ê°œ")    
    return possible_contours

def find_chars(contour_list):
    MAX_DIAG_MULTIPLYER = 4
    MAX_ANGLE_DIFF = 12.0
    MAX_AREA_DIFF = 0.4
    MAX_WIDTH_DIFF = 0.6
    MAX_HEIGHT_DIFF = 0.2
    MIN_N_MATCHED = 4

    matched_result_idx = []

    for c1  in contour_list:
        matched_contours_idx = []
        for c2 in contour_list:
            if c1['idx'] == c2['idx']: # ê°™ì€ contour ë¹„êµì‹œ continue
                continue;

            dx = abs(c1['cx'] - c2['cx'])
            dy = abs(c1['cy'] - c2['cy'])

            diagonal_length = np.sqrt(c1['w'] ** 2 + c1['h'] ** 2)

            distance = np.linalg.norm(np.array([c1['cx'], c1['cy']]) - np.array([c2['cx'], c2['cy']]))
            if dx == 0:
                angle_diff = 90
            else:
                angle_diff = np.degrees(np.arctan(dy / dx))
            area_diff = abs(c1['w'] * c1['h'] - c2['w'] * c2['h']) / (c1['w'] * c1['h'])
            width_diff = abs(c1['w'] - c2['w']) / c1['w']
            height_diff = abs(c1['h'] - c2['h']) / c1['h']
        
            if distance < diagonal_length * MAX_DIAG_MULTIPLYER \
            and angle_diff < MAX_ANGLE_DIFF and area_diff < MAX_AREA_DIFF \
            and width_diff < MAX_WIDTH_DIFF and height_diff < MAX_HEIGHT_DIFF:
                matched_contours_idx.append(c2['idx'])
                
        matched_contours_idx.append(c1['idx'])
        
        if len(matched_contours_idx) < MIN_N_MATCHED:
            continue
            
        matched_result_idx.append(matched_contours_idx)
        
        unmatched_contour_idx = []
        for d4 in contour_list:
            if d4['idx'] not in matched_contours_idx:
                unmatched_contour_idx.append(d4['idx'])
        
        unmatched_contour = np.take(possible_contours, unmatched_contour_idx)
        
        recursive_contour_list = find_chars(unmatched_contour)
        
        for idx in recursive_contour_list:
            matched_result_idx.append(idx)
            
        break
        
    return matched_result_idx

cv2.namedWindow("Frame", cv2.WINDOW_NORMAL)  # ì°½ í¬ê¸° ì¡°ì ˆ ê°€ëŠ¥í•˜ê²Œ ì„¤ì •
cv2.resizeWindow("Frame", 600, 480)         # ì›í•˜ëŠ” í•´ìƒë„ë¡œ ì°½ í¬ê¸° ì„¤ì •
cap = cv2.VideoCapture("http://192.168.0.7:81/stream")
# cap =  cv2.VideoCapture(0)
frame_count = 0
while True:
    start_time = time.time()
    frame_count += 1
    if frame_count % 5 != 0:
        continue
    ret, frame = cap.read()
    if not ret:
        break
    if ret:
        # í‘ë°± ì´ë¯¸ì§€ë¡œ ë³€í™˜
        blur_frame = cv2.GaussianBlur(frame, (5, 5), sigmaX=0)
        gray_frame = cv2.cvtColor(blur_frame, cv2.COLOR_BGR2GRAY)

        # Thresholding
        _, thresh_blur_frame = cv2.threshold(gray_frame, 215, 255, cv2.THRESH_BINARY)
        # ìœ¤ê³½ì„  ì°¾ê¸°
        contours_blur, _ = cv2.findContours(thresh_blur_frame, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
        temp_result_blur = np.zeros(frame.shape, dtype=np.uint8)
        # ìœ¤ê³½ì„  ê·¸ë¦¬ê¸°
        cv2.drawContours(temp_result_blur, contours_blur, contourIdx=-1, color=(255,255,255))
        cv2.imshow("t", temp_result_blur)
        contours_dict = draw_contours(contours_blur) 
        possible_contours = find_possible_contours(contours_dict)
        temp_result_blur = np.zeros(frame.shape, dtype=np.uint8)

        result_idx = find_chars(possible_contours)
        matched_result = []
        for idx_list in result_idx:
            matched_result.append(np.take(possible_contours, idx_list))
        plate_region = np.zeros(frame.shape, dtype=np.uint8)
        for group in matched_result:
            x_min = min([d['x'] for d in group])
            y_min = min([d['y'] for d in group])
            x_max = max([d['x'] + d['w'] for d in group])
            y_max = max([d['y'] + d['h'] for d in group])

            # ë²ˆí˜¸íŒ ì „ì²´ ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)
            plate_region = frame[y_min:y_max, x_min:x_max]
        cv2.imshow("Frame", frame)
        flipped = cv2.flip(plate_region, 1)
        cv2.imshow("plate_region", flipped)


        # # ocrì„ ìœ„í•œ ë²ˆí˜¸íŒ í™•ëŒ€ ì´ë¯¸ì§€
        gray = cv2.cvtColor(flipped, cv2.COLOR_BGR2GRAY)
        gray = cv2.resize(gray, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)  # í™•ëŒ€
        blur = cv2.GaussianBlur(gray, (3, 3), 0)  # ë…¸ì´ì¦ˆ ì œê±°
        _, thresh = cv2.threshold(blur, 121, 255, cv2.THRESH_BINARY)  # ì´ì§„í™”

        # OCR
        pytesseract.pytesseract.tesseract_cmd = r"C:\Dev\Tool\Tesseract-OCR\tesseract.exe"
        chars = pytesseract.image_to_string(thresh, lang='kor', config='--psm 7 --oem 0')
        print(f"[DEBUG]ğŸ“„ ì¶”ì¶œëœ í…ìŠ¤íŠ¸: {chars.strip()}")
        plate_number = chars.strip()
        if not plate_number:
            continue
        # cv2.imshow(plate_region, cmap='gray')s
    if cv2.waitKey(1) & 0XFF == ord('q'):
        break



    # mqtt ì „ì†¡
    ## ë²ˆí˜¸íŒ í˜•ì‹ 000ê°€000 ì´ë©´ ì „ì†¡
        
    # ë²ˆí˜¸íŒ ì •ë³´ ë³´ëƒ„
    if plate_number and re.match(pattern, plate_number):
        now = time.time()
        if plate_number != last_plate or (now - last_time) > cooldown:
            result = client.publish(topic, plate_number)
            result.wait_for_publish()

            # ì „ì†¡ ì™„ë£Œ í™•ì¸ 
            if result.rc == mqtt.MQTT_ERR_SUCCESS:
                last_plate = plate_number
                print("ë²ˆí˜¸íŒ ì „ì†¡ ì™„ë£Œ")
            else:
                print(f"ë²ˆí˜¸íŒ ì „ì†¡ ì‹¤íŒ¨, ì½”ë“œ: {result.rc}")
        else:
            print(f"[DEBUG] ì´ë¯¸ ì²˜ë¦¬ëœ ë²ˆí˜¸íŒì…ë‹ˆë‹¤.")
    else:
        print("[DEBUG] ë²ˆí˜¸íŒ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤")

# ì¢…ë£Œ ì‹œ
cap.release()
cv2.destroyAllWindows()
client.loop_stop()
client.disconnect()